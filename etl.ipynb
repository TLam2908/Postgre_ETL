{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from queries_sql import songs_table_insert, artists_table_insert, times_table_insert, users_table_insert, songplays_table_insert, songs_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    conn = psycopg2.connect(\"dbname=sparkifydb user=postgres password=admin123\")\n",
    "    print(\"Connection to the database is successful\")\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get file path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiles(filePath):\n",
    "    all_files = []\n",
    "    # root: đường dẫn thư mục hiện tại\n",
    "    # dirs: danh sách thư mục con\n",
    "    # files: danh sách file trong thư mục hiện tại\n",
    "    for root, dirs, files in os.walk(filePath):\n",
    "        # print(root, dirs, files)\n",
    "        files = glob.glob(os.path.join(root, '*.json')) \n",
    "        for f in files:\n",
    "            all_files.append(os.path.abspath(f))\n",
    "        \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process song_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = []\n",
    "\n",
    "for song_path in getFiles('data/song_data'):\n",
    "    song_data = pd.read_json(song_path, lines=True)\n",
    "    song_df.append(song_data)\n",
    "\n",
    "songs_df = pd.concat(song_df)\n",
    "songs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract to songs table (convert into list and insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    song_df = songs_df[['song_id', 'title', 'artist_id', 'year', 'duration']]\n",
    "    for i, row in song_df.iterrows():\n",
    "        print(row)\n",
    "        cur.execute(songs_table_insert, list(row))\n",
    "        conn.commit()\n",
    "    print(\"Insert data into song table successfully\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract to artists table (convert into list and insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    artist_df = songs_df[['artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude']]\n",
    "    for i, row in artist_df.iterrows():\n",
    "        cur.execute(artists_table_insert, list(row))\n",
    "        conn.commit()\n",
    "    print(\"Insert data into artist table successfully\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process log_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = []\n",
    "\n",
    "for log_path in getFiles('data/log_data'):\n",
    "    log_data = pd.read_json(log_path, lines=True)\n",
    "    log_df.append(log_data)\n",
    "\n",
    "logs_df = pd.concat(log_df)\n",
    "logs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract to times table\n",
    "    - Filter records by NextSong action\n",
    "    - Convert the ts timestamp column to datetime\n",
    "    - Extract the timestamp, hour, day, week of year, month, year, and weekday from the ts column and set time_data to a list containing these values in order\n",
    "    - Specify labels for these columns and set to column_labels\n",
    "    - Create a dataframe, time_df, containing the time data for this file by combining column_labels and time_data into a dictionary and converting this into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = logs_df[logs_df['page'] == 'NextSong']\n",
    "t = pd.to_datetime(time_df['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = [(tt.value, tt.hour, tt.day, tt.week, tt.month, tt.year, tt.weekday()) for tt in t]\n",
    "column_labels = ('timestamp', 'hour', 'day', 'week', 'month', 'year', 'weekday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take time values from files and convert into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame(time_data, columns=column_labels)\n",
    "time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Records into times table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i, row in time_df.iterrows():\n",
    "        cur.execute(times_table_insert, list(row))\n",
    "        conn.commit()\n",
    "    print(\"Insert data into time table successfully\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extract to users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    user_df = logs_df[['userId', 'firstName', 'lastName', 'gender', 'level']]\n",
    "    for i, row in user_df.iterrows():\n",
    "        print(list(row))\n",
    "        cur.execute(users_table_insert, list(row))\n",
    "        conn.commit()\n",
    "    print(\"Insert data into user table successfully\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Extract songplays table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    for index, row in logs_df.iterrows():\n",
    "        # Tham so truyen vao cau lenh sql\n",
    "        cur.execute(songs_select, (row.song, row.artist, row.length))\n",
    "        results = cur.fetchone()    \n",
    "        \n",
    "        if results:\n",
    "            songid, artistid = results\n",
    "        else:\n",
    "            songid, artistid = None, None\n",
    "\n",
    "        # insert songplay record\n",
    "        songplay_data = (index, row['ts'], row['userId'], row['level'], songid, artistid, row['sessionId'],\n",
    "                     row['location'], row['userAgent'])\n",
    "        print(song_data)\n",
    "        cur.execute(songplays_table_insert, songplay_data)\n",
    "        conn.commit()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
